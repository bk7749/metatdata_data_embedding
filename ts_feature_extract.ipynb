{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import *\n",
    "import operator\n",
    "import matplotlib\n",
    "reload(matplotlib)\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt   \n",
    "import pickle as pkl\n",
    "import shelve\n",
    "import re\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics#v_measure_score\n",
    "import scipy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import pp\n",
    "import shelve\n",
    "from collections import OrderedDict\n",
    "\n",
    "# ML modules\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.mixture import DPGMM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "\n",
    "# Custom modules\n",
    "from bd_wrapper import BDWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sensor_dict = shelve.open('metadata/bacnet_devices.shelve','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buildingName = 'ebu3b'\n",
    "naeDict = dict()\n",
    "naeDict['bonner'] = [\"607\", \"608\", \"609\", \"557\", \"610\"]\n",
    "naeDict['ap_m'] = ['514', '513','604']\n",
    "naeDict['bsb'] = ['519', '568', '567', '566', '564', '565']\n",
    "naeDict['ebu3b'] = [\"505\", \"506\"]\n",
    "naeList = naeDict[buildingName]\n",
    "missingSrcidList = list()\n",
    "with open('missingsrcidlist.csv', 'rb') as fp:\n",
    "    reader = csv.reader(fp)\n",
    "    for row in reader:\n",
    "        missingSrcidList.append(row[0])\n",
    "outputFilename = 'data/fe_' + buildingName + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(srcidList, dummy):\n",
    "    import feature_extractor as fe\n",
    "    import shelve\n",
    "    resultList = list()\n",
    "    for srcid in srcidList:\n",
    "        #print srcid\n",
    "        filename = 'rawdata/ebu3b/'+srcid+'.shelve'\n",
    "        #with open('rawdata/ebu3b/'+srcid+'.pkl', 'rb') as fp:\n",
    "            #ts = pickle.load(fp)\n",
    "        ts = shelve.open(filename)['data']\n",
    "        #print \"hello\"\n",
    "        \n",
    "        resultList.append((srcid, fe.get_features(ts)))\n",
    "        #resultList.append((srcid, 10))\n",
    "        ts = None\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def temp_func(srcid):\n",
    "    return (srcid, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uuidList = list()\n",
    "srcidList = list()\n",
    "for nae in naeList:\n",
    "    deviceList = sensor_dict[nae]\n",
    "    for sensor in deviceList['objs'][1:]:\n",
    "        h_obj = sensor['props']\n",
    "        srcid = nae + '_' + str(h_obj['type']) + '_' + str(h_obj['instance'])\n",
    "        if not srcid in missingSrcidList:\n",
    "            srcidList.append(srcid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4573\n"
     ]
    }
   ],
   "source": [
    "print len(srcidList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ncpus = 4\n",
    "#rangeList = list()\n",
    "\n",
    "#sensorsNum = len(srcidList)\n",
    "#for i in range(0,ncpus):\n",
    "#    rangeList.append(range(sensorsNum/ncpus*(i+1) - sensorsNum/ncpus, sensorsNum/ncpus*(i+1)))\n",
    "\n",
    "#srcidListList = list()\n",
    "#for oneRange in rangeList:\n",
    "#oneList =  [srcidList[i] for i in oneRange]\n",
    "#    srcidListList.append(oneList)\n",
    "    \n",
    "#p = Pool(ncpus)\n",
    "#tempDict = dict((p.map(extract_features, srcidListList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============\n",
      "=-============\n"
     ]
    }
   ],
   "source": [
    "#p = Pool(4)\n",
    "#tempDict = dict((p.map(extract_features, srcidList)))\n",
    "\n",
    "ppservers = ()\n",
    "ncpus = 4\n",
    "rangeList = list()\n",
    "\n",
    "#srcidList = ['505_0_3000043', '506_0_3000026', '505_0_3000003', '506_0_3000023',  '506_0_3000027']\n",
    "\n",
    "sensorsNum = len(srcidList)\n",
    "for i in range(0,ncpus):\n",
    "    rangeList.append(range(sensorsNum/ncpus*(i+1) - sensorsNum/ncpus, sensorsNum/ncpus*(i+1)))\n",
    "print \"==============\"\n",
    "\n",
    "jobServer = pp.Server(ncpus, ppservers=ppservers)\n",
    "jobList = list()\n",
    "for oneRange in rangeList:\n",
    "    #print [srcidList[i] for i in oneRange]\n",
    "    jobList.append(jobServer.submit(extract_features, ([srcidList[i] for i in oneRange], True)))\n",
    "\n",
    "resultList = list()\n",
    "resultList = [0,0,0,0]\n",
    "for i, job in enumerate(jobList):\n",
    "    resultList[i] = job()\n",
    "#r1 = jobList[0]()\n",
    "#r2 = jobList[1]()\n",
    "jobServer.wait()\n",
    "print \"=-============\"\n",
    "#print r1\n",
    "#print r2\n",
    "\n",
    "dictList = list()\n",
    "#print resultList\n",
    "for result in resultList:\n",
    "#    print \"result: \", result\n",
    "    dictList = dictList + result\n",
    "resultDict = dict(dictList)\n",
    "#print resultDict\n",
    "\n",
    "#job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "#j1 = job_server.submit(extract_features, srcidList[0:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(outputFilename, 'wb') as fp:\n",
    "    pickle.dump(resultDict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('506_0_3000485', [[78.090000000000003], [70.310000000000002], [73.23721682205932], [7.7800000000000011], [1.3343221657969844], [1], [0.09193601197209314], [0.08667059921117616], [0.2309582309582308], [0.4558330478773272], [41.127274720277448], [10.167352010178156]]), ('506_1_3000497', [[330.0], [330.0], [330.0], [0.0], [0.0], [7], [0.0], [0.0], -999999, -999999, [41.127274720277448], [0.0]]), ('506_1_3000493', [[70.0], [68.0], [69.51229914699465], [2.0], [0.4257477529643602], [0], [0.03649067915102501], [0.0354748255850961], [0.0], [0.2815235026816336], [41.127274720277448], [1.4747474747510783]]), ('506_1_3000494', [[3.1400000000000001], [-2.5499999999999998], [-0.047014481253718446], [5.6899999999999995], [0.2068900312037349], [3], [0.07643021840557931], [0.08918966463222437], [0.0], [0.08265730251103016], [41.127274720277448], [16.398902542401341]])]\n"
     ]
    }
   ],
   "source": [
    "## TEST FE\n",
    "import feature_extractor \n",
    "reload(feature_extractor)\n",
    "import feature_extractor as fe\n",
    "import FATS\n",
    "\n",
    "\n",
    "srcidDict = OrderedDict()\n",
    "srcidDict['ZT'] = '506_0_3000485' # 2150 ZT\n",
    "srcidDict['OCM'] = '506_1_3000497' # 2150 occ clg max\n",
    "srcidDict['CS'] = '506_1_3000493' # 2150 TS\n",
    "srcidDict['DC'] = '506_1_3000494' # 2150 \n",
    "\n",
    "fat = FATS.FeatureSpace(Data=['magnitude', 'time'], featureList=[#'Mean', 'Amplitude', 'Skew', \n",
    "                                                                 #'Meanvariance', \n",
    "                                                                 #'PeriodLS' \n",
    "                                                                 #'Std', \n",
    "                                                                 #'MaxSlope', \n",
    "                                                                 'SmallKurtosis'\n",
    "                                                                ])\n",
    "#for pointType, srcid in srcidDict.iteritems():\n",
    "#    filename = 'rawdata/ebu3b/'+srcid+'.shelve'\n",
    "#    ts = shelve.open(filename)['data']\n",
    "#    #print pointType, fe.get_fft(ts)\n",
    "#    ts = np.asarray([ts.values, ts.index.values])\n",
    "#    result = fat.calculateFeature(ts).result()\n",
    "#    print pointType, result\n",
    "\n",
    "result = extract_features(srcidDict.values(), True)\n",
    "print result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
